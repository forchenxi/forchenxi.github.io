<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="deep learning,CNN,computer vision,data augmentation,">










<meta name="description" content="本文章参考《Python深度学习》 深度学习用于计算机视觉(上篇)本系列文章内容较多，共分为三篇，主要包括以下内容：   理解卷积神经网络（convnet） 使用数据增强来降低过拟合  使用预训练的卷积神经网络进行特征提取  微调预训练的卷积神经网络  将卷积神经网络学到的内容及其如何做出分类决策可视化  上篇主要包括前两点，中篇包括三四点，下篇主要围绕第五点。 卷积神经网络简介我们先通过一个简单">
<meta name="keywords" content="deep learning,CNN,computer vision,data augmentation">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习用于计算机视觉(上篇)">
<meta property="og:url" content="http://yoursite.com/2021/02/05/dl-computer-vision1/index.html">
<meta property="og:site_name" content="Sunrise">
<meta property="og:description" content="本文章参考《Python深度学习》 深度学习用于计算机视觉(上篇)本系列文章内容较多，共分为三篇，主要包括以下内容：   理解卷积神经网络（convnet） 使用数据增强来降低过拟合  使用预训练的卷积神经网络进行特征提取  微调预训练的卷积神经网络  将卷积神经网络学到的内容及其如何做出分类决策可视化  上篇主要包括前两点，中篇包括三四点，下篇主要围绕第五点。 卷积神经网络简介我们先通过一个简单">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p1.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p2.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p3.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p4.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p5.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p6.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p7.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p8.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p9.png">
<meta property="og:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p10.png">
<meta property="og:updated_time" content="2021-03-12T10:30:11.622Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习用于计算机视觉(上篇)">
<meta name="twitter:description" content="本文章参考《Python深度学习》 深度学习用于计算机视觉(上篇)本系列文章内容较多，共分为三篇，主要包括以下内容：   理解卷积神经网络（convnet） 使用数据增强来降低过拟合  使用预训练的卷积神经网络进行特征提取  微调预训练的卷积神经网络  将卷积神经网络学到的内容及其如何做出分类决策可视化  上篇主要包括前两点，中篇包括三四点，下篇主要围绕第五点。 卷积神经网络简介我们先通过一个简单">
<meta name="twitter:image" content="http://yoursite.com/2021/02/05/dl-computer-vision1/p1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2021/02/05/dl-computer-vision1/">





  <title>深度学习用于计算机视觉(上篇) | Sunrise</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Sunrise</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">`长路漫漫，唯剑作伴`</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/02/05/dl-computer-vision1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="chenxi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Sunrise">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">深度学习用于计算机视觉(上篇)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-02-05T18:09:54+08:00">
                2021-02-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><em>本文章参考《Python深度学习》</em></p>
<h3 id="深度学习用于计算机视觉-上篇"><a href="#深度学习用于计算机视觉-上篇" class="headerlink" title="深度学习用于计算机视觉(上篇)"></a>深度学习用于计算机视觉(上篇)</h3><p>本系列文章内容较多，共分为三篇，主要包括以下内容： </p>
<ul>
<li>理解卷积神经网络（convnet）</li>
<li>使用数据增强来降低过拟合 </li>
<li>使用预训练的卷积神经网络进行特征提取 </li>
<li>微调预训练的卷积神经网络 </li>
<li>将卷积神经网络学到的内容及其如何做出分类决策可视化</li>
</ul>
<p>上篇主要包括前两点，中篇包括三四点，下篇主要围绕第五点。</p>
<h4 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h4><p>我们先通过一个简单的例子来展示什么卷积神经网络，它是<code>Conv2D</code>层和<code>MaxPooling2D</code>层的堆叠。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>卷积神经网络接收形状为 (image_height, image_width, image_channels) 的输入张量（不包括批量维度）。本例中设置卷积神经网络处理大小为 (28, 28, 1) 的输入张量， 这正是 MNIST 图像的格式。</p>
<p><code>model.summary()</code>可以用来查看卷积神经网络的架构</p>
<a id="more"></a>
<p><img src="/2021/02/05/dl-computer-vision1/p1.png" alt></p>
<p>可以看到，每个 Conv2D 层和 MaxPooling2D 层的输出都是一个形状为 (height, width, channels) 的 3D 张量。宽度和高度两个维度的尺寸通常会随着网络加深而变小。<strong>通道数量由传 入 Conv2D 层的第一个参数所控制（32 或 64）</strong>。</p>
<p>下一步是将最后的输出张量［大小为 (3, 3, 64)］输入到一个密集连接分类器网络中， 即 Dense 层的堆叠，你已经很熟悉了。这些分类器可以处理 1D 向量，而当前的输出是 3D 张量。 首先，我们<strong>需要将 3D 输出展平为 1D</strong>，然后在上面添加几个 Dense 层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>))</span><br></pre></td></tr></table></figure>
<p>我们将进行 10 类别分类，最后一层使用带 10 个输出的 softmax 激活。现在网络的架构如下</p>
<p><img src="/2021/02/05/dl-computer-vision1/p2.png" alt></p>
<p>如你所见，在进入两个 Dense 层之前，形状 (3, 3, 64) 的输出被展平为形状 (576,) 的向量(3x3x64=576)。 下面我们在 MNIST 数字图像上训练这个卷积神经网络。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"></span><br><span class="line">(train_images, train_lables), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">print(train_images.shape)  <span class="comment"># (60000, 28, 28)</span></span><br><span class="line">print(train_lables.shape)  <span class="comment"># (60000,)</span></span><br><span class="line">train_images = train_images.reshape((<span class="number">60000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>))</span><br><span class="line">train_images = train_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></span><br><span class="line">test_images = test_images.reshape(<span class="number">10000</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br><span class="line">test_images = test_images.astype(<span class="string">'float32'</span>) / <span class="number">255</span></span><br><span class="line"></span><br><span class="line">train_lables = to_categorical(train_lables)</span><br><span class="line">test_labels = to_categorical(test_labels)</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line">model.fit(train_images, train_lables, epochs=<span class="number">5</span>, batch_size=<span class="number">64</span>)</span><br><span class="line">test_loss, test_acc = model.evaluate(test_images, test_labels)</span><br><span class="line">print(test_acc)</span><br></pre></td></tr></table></figure>
<p>这里的训练集数据的shape是 (60000, 28, 28)，而输入到神经网络的数据格式是<code>4D</code>张量，(samples, height, width, channels)，所以这里使用reshape转换为目标格式(reshape一定要在明确自己的需求的情况下使用，我在前面的文章中写过我在自己处理验证码数据时，错误使用reshape带来的大坑)</p>
<p>另外，这里除以255，<code>to_categorical</code>等知识前面的文章其实基本都已经介绍过，这里就不再一一细说。</p>
<p>这里使用卷积神经网络训练手写数字分类，能达到99%的准确率，相比直接使用全连接层网络，效果得到了一定的提升(因为这个任务比较简单，使用全连接层网络的准确率也是比较高的)</p>
<h5 id="卷积运算"><a href="#卷积运算" class="headerlink" title="卷积运算"></a>卷积运算</h5><p>密集连接层和卷积层的根本区别在于，<strong>Dense 层从输入特征空间中学到的是全局模式</strong>（比如对于 MNIST 数字，全局模式就是涉及所有像素的模式），而<strong>卷积层学到的是局部模式</strong>（见下图），对于图像来说，学到的就是在输入图像的二维小窗口中发现的模式。在上面的例子中， 这些窗口的大小都是 3×3。</p>
<p><img src="/2021/02/05/dl-computer-vision1/p3.png" alt></p>
<p>这个重要特性使卷积神经网络具有以下两个有趣的性质。 </p>
<ul>
<li><p>卷积神经网络学到的模式具有<strong>平移不变性</strong>（translation invariant）。<strong>卷积神经网络在图像右下角学到某个模式之后，它可以在任何地方识别这个模式</strong>，比如左上角。对于密集连 接网络来说，如果模式出现在新的位置，它只能重新学习这个模式。这使得卷积神经网络在处理图像时可以高效利用数据（因为视觉世界从根本上具有平移不变性），它只需要更少的训练样本就可以学到具有泛化能力的数据表示。</p>
</li>
<li><p>卷积神经网络可以学到<strong>模式的空间层次结构</strong>（spatial hierarchies of patterns），见下图。 第一个卷积层将学习较小的局部模式（比如边缘），第二个卷积层将学习由第一层特征组成的<strong>更大的模式</strong>，以此类推。这使得卷积神经网络可以有效地学习<strong>越来越复杂、越来越抽象</strong>的视觉概念（因为视觉世界从根本上具有空间层次结构）。</p>
</li>
</ul>
<p>对于包含两个空间轴（高度和宽度）和一个深度轴（也叫通道轴）的 3D 张量，其卷积也叫<strong>特征图</strong>（feature map）。卷积运算从输入特征图中提取图块，并对所有这些图块应用相同的变换，生成<strong>输出特征图</strong>（output feature map）。该输出特征图仍是一个 3D 张量，具有宽度和高度，其深度可以任意取值，因为<strong>输出深度是层的参数</strong>，深度轴的不同通道不再像 RGB 输入那样代表特定颜色，而是<strong>代表过滤器</strong> （filter）（<strong>等于过滤器数量</strong>）。</p>
<p><img src="/2021/02/05/dl-computer-vision1/p4.png" alt></p>
<p>卷积由以下两个关键参数所定义。 </p>
<ul>
<li><strong>从输入中提取的图块尺寸</strong>：这些图块的大小通常是 3×3 或 5×5。本例中为 3×3，这是很常见的选择。 </li>
<li><strong>输出特征图的深度：卷积所计算的过滤器的数量</strong>。本例第一层的深度为 32，最后一层的深度是 64。</li>
</ul>
<p>对于 Keras 的 Conv2D 层，这些参数都是向层传入的前几个参数：<code>Conv2D(output_depth, (window_height, window_width))</code>。</p>
<p>卷积的工作原理：在 3D 输入特征图上滑动（slide）这些 3×3 或 5×5 的窗口，在每个可能的位置停止并提取周围特征的 3D 图块［形状为 (window_height, window_width, input_ depth)］。然后每个 3D 图块与学到的<strong>同一个权重矩阵［叫作卷积核</strong>（convolution kernel）］做 张量积，<strong>转换成形状为 (output_depth,) 的 1D 向量</strong>。然后对所有这些向量进行空间重组， 使其转换为形状为 (height, width, output_depth) 的 3D 输出特征图。输出特征图中的 每个空间位置都对应于输入特征图中的相同位置（比如输出的右下角包含了输入右下角的信 息）。举个例子，利用 3×3 的窗口，向量 output[i, j, :] 来自 3D 图块 input[i-1:i+1, j-1:j+1, :]。整个过程详见图。</p>
<p><img src="/2021/02/05/dl-computer-vision1/p5.png" alt></p>
<p><em>以上过程描述非常形象，多读几遍有助于理解，也可以和前面的一篇CNN原理一起看</em></p>
<p>注意，输出的宽度和高度可能与输入的宽度和高度不同。不同的原因可能有两点。</p>
<ul>
<li><strong>边界效应</strong>，可以通过对输入特征图进行填充来抵消。 </li>
<li><strong>使用了步幅</strong>（stride）。</li>
</ul>
<p>这两个概念在上篇CNN文章已经介绍的很清楚了，并且是比较简单的概念这里就不再说了。</p>
<h5 id="最大池化"><a href="#最大池化" class="headerlink" title="最大池化"></a>最大池化</h5><p>每个 MaxPooling2D 层之后，特征图的尺寸都会减半。例如，在第一个 MaxPooling2D 层之前，特征图的尺寸是 26×26，但最大池化运算将其减半为 13×13。这就是最大池化的作用：<strong>对特征图进行下采样</strong>，与步进卷积类似。</p>
<p>最大池化是从输入特征图中提取窗口，并<strong>输出每个通道的最大值</strong>。它的概念与卷积类似， 但是最大池化使用硬编码的 max 张量运算对局部图块进行变换，而不是使用学到的线性变换（卷积核）。最大池化与卷积的最大不同之处在于，<strong>最大池化通常使用 2×2 的窗口和步幅 2</strong>，其目的是将特征图下采样 2 倍。与此相对的是，卷积通常使用 3×3 窗口和步幅 1。</p>
<p>虽然前面文章也讲过最大池化，但是书中这里从神经网络架构的角度来重新理解了一下为什么需要池化层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model_no_max_pool = models.Sequential()</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>,</span><br><span class="line"> input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model_no_max_pool.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br></pre></td></tr></table></figure>
<p>如果没有最大池化层，模型的架构如下</p>
<p><img src="/2021/02/05/dl-computer-vision1/p6.png" alt></p>
<p>这种架构有什么问题？有如下两点问题。</p>
<ul>
<li><p>这种架构不利于学习特征的空间层级结构。第三层的 3×3 窗口中只包含初始输入的 7×7 窗口中所包含的信息。<strong>卷积神经网络学到的高级模式相对于初始输入来说仍然很小</strong>， 这可能不足以学会对数字进行分类（你可以试试仅通过 7 像素×7 像素的窗口观察图像 来识别其中的数字）。我们需要<strong>让最后一个卷积层的特征包含输入的整体信息</strong>。</p>
</li>
<li><p>最后一层的特征图对每个样本共有 22×22×64=30 976 个元素。这太多了。如果你将其 展平并在上面添加一个大小为 512 的 Dense 层，那一层将会有 1580 万个参数。这对于这样一个小模型来说太多了，会导致严重的过拟合。 简而言之，使用下采样的原因，<strong>一是减少需要处理的特征图的元素个数</strong>，二是通过让连续卷积层的<strong>观察窗口越来越大（即窗口覆盖原始输入的比例越来越大）</strong>，从而引入空间过滤器的层级结构。</p>
</li>
</ul>
<p>注意，最大池化不是实现这种下采样的唯一方法，使用步幅或者平均池化也都可以，但是最大池化的效果往往是最好的。</p>
<h4 id="在小数据集上从头开始训练一个卷积神经网络"><a href="#在小数据集上从头开始训练一个卷积神经网络" class="headerlink" title="在小数据集上从头开始训练一个卷积神经网络"></a>在小数据集上从头开始训练一个卷积神经网络</h4><p>本例我们将重点讨论猫狗图像分类，数据集中包含 4000 张猫和狗的图像 （2000 张猫的图像，2000 张狗的图像）。我们将 2000 张图像用于训练，1000 张用于验证，1000 张用于测试。</p>
<p>训练所需的样本数量与你所要训练网络的大小和深度有关，只用几十个样本训练卷积神经网络就解决一个复杂问题是不可能的，但如果模型很小， 并做了很好的正则化，同时任务非常简单，那么几百个样本可能就足够了。</p>
<h5 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h5><p>这里用到的猫狗分类数据集不在keras中，可以从<code>https://www.kaggle.com/ c/dogs-vs-cats/data</code>下载原始数据集，需要注册账号，并且容易验证码刷不出来，不过网上有很多分享的百度网盘下载链接也可以下载。</p>
<p>这些图像都是中等分辨率的彩色 JPEG 图像，下载数据并解压之后，你需要创建一个新数据集，其中包含三个子集：每个类别各1000个样本的训练集、每个类别各500个样本的验证集和每个类别各500个样本的测试集。</p>
<p>划分数据集的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">original_dataset_dir = <span class="string">'D:/python_project/深度学习/keras_t/samples/kaggle_original_data'</span></span><br><span class="line">base_dir = <span class="string">'D:/python_project/深度学习/keras_t/samples/cats_and_dogs_small'</span></span><br><span class="line">os.mkdir(base_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别对应划分后的训练、验证和测试的目录</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'train'</span>)</span><br><span class="line">os.mkdir(train_dir)</span><br><span class="line">validation_dir = os.path.join(base_dir, <span class="string">'validation'</span>)</span><br><span class="line">os.mkdir(validation_dir)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'test'</span>)</span><br><span class="line">os.mkdir(test_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 猫的训练图像目录</span></span><br><span class="line">train_cats_dir = os.path.join(train_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(train_cats_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 狗的训练图像目录</span></span><br><span class="line">train_dogs_dir = os.path.join(train_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(train_dogs_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 猫的验证图像目录</span></span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(validation_cats_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 狗的验证图像目录</span></span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(validation_dogs_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 猫的测试图像目录</span></span><br><span class="line">test_cats_dir = os.path.join(test_dir, <span class="string">'cats'</span>)</span><br><span class="line">os.mkdir(test_cats_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 狗的测试图像分类</span></span><br><span class="line">test_dogs_dir = os.path.join(test_dir, <span class="string">'dogs'</span>)</span><br><span class="line">os.mkdir(test_dogs_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将前1000张猫的图像复制给train_cats_dir</span></span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(train_cats_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将接下来500张猫的图像复制到validation_cats_dir</span></span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(validation_cats_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将接下来500张猫的图像复制到test_cats_dir</span></span><br><span class="line">fnames = [<span class="string">'cat.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(test_cats_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将前1000张狗的图像复制到train_dogs_dir</span></span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(train_dogs_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将接下来500张狗的图像复制到validation_dogs_dir</span></span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>, <span class="number">1500</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(validation_dogs_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将接下来500张狗的图像复制到test_dogs_dir</span></span><br><span class="line">fnames = [<span class="string">'dog.&#123;&#125;.jpg'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1500</span>, <span class="number">2000</span>)]</span><br><span class="line"><span class="keyword">for</span> fname <span class="keyword">in</span> fnames:</span><br><span class="line">    src = os.path.join(original_dataset_dir, fname)</span><br><span class="line">    dst = os.path.join(test_dogs_dir, fname)</span><br><span class="line">    shutil.copyfile(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看每个分组(训练、验证、测试)分别包含多少张图像</span></span><br><span class="line">print(<span class="string">'total training cat images:'</span>, len(os.listdir(train_cats_dir)))</span><br><span class="line">print(<span class="string">'total training dog images:'</span>, len(os.listdir(train_dogs_dir)))</span><br><span class="line">print(<span class="string">'total validation cat images:'</span>, len(os.listdir(validation_cats_dir)))</span><br><span class="line">print(<span class="string">'total validation dog images:'</span>, len(os.listdir(validation_dogs_dir)))</span><br><span class="line">print(<span class="string">'total test cat images:'</span>, len(os.listdir(test_cats_dir)))</span><br><span class="line">print(<span class="string">'total test dog images:'</span>, len(os.listdir(test_dogs_dir)))</span><br><span class="line"></span><br><span class="line">total training cat images: <span class="number">1000</span></span><br><span class="line">total training dog images: <span class="number">1000</span></span><br><span class="line">total validation cat images: <span class="number">500</span></span><br><span class="line">total validation dog images: <span class="number">500</span></span><br><span class="line">total test cat images: <span class="number">500</span></span><br><span class="line">total test dog images: <span class="number">500</span></span><br></pre></td></tr></table></figure>
<p>这个步骤不写代码，手动操作也是可以的。</p>
<h5 id="构建网络"><a href="#构建网络" class="headerlink" title="构建网络"></a>构建网络</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<p>前面已经介绍了卷积神经网络是<code>Conv2D</code>层和<code>MaxPooling2D</code>层的堆叠；我们再来看一下特征图的维度如何随着每层变化</p>
<p><img src="/2021/02/05/dl-computer-vision1/p7.png" alt></p>
<p>经过前面的学习基本也可以理解这个图中每个数字的由来(除了param那一列)，因为卷积大小是(3, 3)所以每次卷积后高和宽减小2，最大池化后高和宽减半，输出通道数量等于卷积核数量。在编译这一步，和前面一样，我们将使用 RMSprop 优化器。因为网络最后一层是单一 sigmoid 单元，所以我们将使用二元交叉熵作为损失函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">              optimizer=optimizers.RMSprop(lr=<span class="number">1e-4</span>), </span><br><span class="line">              metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure>
<h5 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h5><p>将数据输入神经网络之前，应该将数据格式化为经过预处理的浮点数张量，现在数据以JPEG文件的形式保存在硬盘中，所以数据预处理步骤大致如下：</p>
<p>1、读取图像文件</p>
<p>2、将JPEG文件解码为RGB像素网格</p>
<p>3、将这些像素网格转换为浮点数张量</p>
<p>4、将像素值(0~255范围内)缩放到[0, 1]区间(正如你所见，神经网络喜欢处理较小的输入值)</p>
<p>这些步骤可能看起来有点吓人，但幸运的是，Keras 拥有自动完成这些步骤的工具。Keras 有一个图像处理辅助工具的模块，位于 keras.preprocessing.image。特别地，它包含 ImageDataGenerator 类，可以快速创建 Python 生成器，能够将硬盘上的图像文件自动转换 为预处理好的张量批量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将所有图像乘以1/255缩放</span></span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将所有图像调整为150x150</span></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为使用了binary_crossentropy损失，所以需要用二进制标签</span></span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    validation_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>flow_from_directory(directory): 以文件夹路径为参数,生成经过数据提升/归一化后的数据,在一个无限循环中无限产生batch数据，参数及其含义</p>
<ul>
<li>directory: 目标文件夹路径,对于每一个类,该文件夹都要<strong>包含一个子文件夹</strong>，子文件夹中任何JPG、PNG、BNP、PPM的图片都会被生成器使用</li>
<li>target_size: 整数tuple,默认为(256, 256). 图像将<strong>被resize成该尺寸</strong></li>
<li>color_mode: 颜色模式,为”grayscale”,”rgb”之一,默认为”rgb”.代表这些图片是否会被转换为单通道或三通道的图片.</li>
<li>classes: 可选参数,为子文件夹的列表,如[‘dogs’,’cats’]默认为None. 若未提供,则该类别列表将从<code>directory</code>下的<strong>子文件夹名称/结构自动推断。每一个子文件夹都会被认为是一个新的类</strong>。(类别的顺序将按照字母表顺序映射到标签值)。通过属性<code>class_indices</code>可获得文件夹名与类的序号的对应字典。</li>
<li>class_mode: “categorical”, “binary”, “sparse”或None之一. 默认为”categorical. 该参数决定了返回的标签数组的形式, “categorical”会返回2D的one-hot编码标签,”binary”返回1D的二值标签.”sparse”返回1D的整数标签,如果为None则不返回任何标签, 生成器将仅仅生成batch数据, 这种情况在使用<code>model.predict_generator()</code>和<code>model.evaluate_generator()</code>等函数时会用到.</li>
<li>batch_size: batch数据的大小,默认32</li>
<li>shuffle: <strong>是否打乱数据</strong>,默认为True</li>
<li>seed: 可选参数,打乱数据和进行变换时的随机数种子</li>
<li>save_to_dir: None或字符串，该参数能让你将提升后的图片保存起来，用以可视化</li>
<li>save_prefix：字符串，保存提升后图片时使用的前缀, 仅当设置了<code>save_to_dir</code>时生效</li>
<li>save_format：”png”或”jpeg”之一，指定保存图片的数据格式,默认”jpeg”</li>
<li>flollow_links: 是否访问子文件夹中的软链</li>
</ul>
<p>一个生成器的输出：生成150x150的RGB图像[形状为(20, 150, 150, 3)]与二进制标签[形状为(20,)]组成的批量。每个批量中包含20个样本(批量大小)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>利用生成器，我们让模型对数据进行拟合。我们将使用fit_generator方法来拟合，它在数据生成器上的效果和fit相同，它的第一个参数是一个Python生成器，可以不停地生成输入和目标组成的批量，比如train_generator。</p>
<p>因为数据是不断生成的，所以Keras模型要知道每一轮需要从生成器中抽取多少个样本，这是steps_per_epoch参数的作用：从生成 器中抽取 steps_per_epoch 个批量后（即运行了 steps_per_epoch 次梯度下降），拟合过程 将进入下一个轮次。本例中，每个批量包含 20 个样本，所以读取完所有 2000 个样本需要 100 个批量。</p>
<p>使用 fit_generator 时，你可以传入一个 validation_data 参数，其作用和在 fit 方 法中类似。值得注意的是，这个参数可以是一个数据生成器，但也可以是 Numpy 数组组成的元 组。如果向 validation_data 传入一个生成器，那么这个生成器应该能够不停地生成验证数 据批量，因此你还需要指定 validation_steps 参数，说明需要从验证生成器中抽取多少个批次用于评估。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'cats_and_dogs_small_1.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>始终在训练完成后保存模型，这是一种良好实践。</p>
<p>我们来分别绘制训练过程中模型在训练数据和验证数据上的损失和精度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">acc = history.history[<span class="string">'acc'</span>]</span><br><span class="line">val_acc = history.history[<span class="string">'val_acc'</span>]</span><br><span class="line">loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(acc)+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>plt.legend()函数主要的作用就是给图加上图例，plt.legend([x,y,z])里面的参数使用的是list的的形式将图表的的名称喂给这个函数；</p>
<p>plt.figure()主要是方便连续画几个图片。</p>
<p><img src="/2021/02/05/dl-computer-vision1/p8.png" alt></p>
<p><img src="/2021/02/05/dl-computer-vision1/p9.png" alt></p>
<p>从这些图像中都能看出过拟合的特征。训练精度随着时间线性增加，直到接近 100%，而验证精度则停留在 70%~72%。验证损失仅在 5 轮后就达到最小值（后面的波动特别大，也不知道啥原因），然后保持不变，而训练损失则 一直线性下降，直到接近于 0。 因为训练样本相对较少（2000 个），所以过拟合是你最关心的问题。前面已经介绍过几种降低过拟合的技巧，比如 dropout 和权重衰减（L2 正则化）。现在我们将使用一种针对于计算机视觉领域的新方法，在用深度学习模型处理图像时几乎都会用到这种方法，它就是<strong>数据增强 （data augmentation）</strong>。</p>
<h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><p>过拟合的原因是学习样本太少，导致无法训练出能够泛化到新数据的模型。如果拥有无限的数据，那么模型能够观察到数据分布的所有内容，这样就永远不会过拟合。<strong>数据增强是从现有的训练样本中生成更多的训练数据，其方法是利用多种能够生成可信图像的随机变换来增加 （augment）样本</strong>。其目标是，模型在训练时不会两次查看完全相同的图像。这让模型能够观察 到数据的更多内容，从而具有更好的泛化能力。 </p>
<p>在 Keras 中，这可以通过对 ImageDataGenerator 实例读取的图像执行多次随机变换来实现。我们先来看一个例子。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>这里只选择了几个参数（想了解更多参数，请查阅 Keras 文档）。我们来快速介绍一下这些参数的含义。</p>
<ul>
<li>rotation_range 是角度值（在 0~180 范围内），表示图像随机旋转的角度范围。</li>
<li>width_shift 和 height_shift 是图像在水平或垂直方向上平移的范围（相对于总宽 度或总高度的比例）。 </li>
<li>shear_range 是随机错切变换的角度。 </li>
<li>zoom_range 是图像随机缩放的范围。 </li>
<li>horizontal_flip 是随机将一半图像水平翻转。如果没有水平不对称的假设（比如真 实世界的图像），这种做法是有意义的。 </li>
<li>fill_mode是用于填充新创建像素的方法，这些新像素可能来自于旋转或宽度/高度平移</li>
</ul>
<p>显示几个随机增强后的图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">fnames = [os.path.join(train_cats_dir, fname) <span class="keyword">for</span> fname <span class="keyword">in</span> os.listdir(train_cats_dir)]</span><br><span class="line">img_path = fnames[<span class="number">3</span>]  <span class="comment"># 选择一张图像进行增强</span></span><br><span class="line"><span class="comment"># 读取图像并调整大小</span></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line"><span class="comment"># 将其转换为形状 (150, 150, 3) 的 Numpy 数组</span></span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line"><span class="comment"># 将其形状改变为 (1, 150, 150, 3)</span></span><br><span class="line">x = x.reshape((<span class="number">1</span>,) + x.shape)</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> datagen.flow(x, batch_size=<span class="number">1</span>):</span><br><span class="line">    plt.figure(i)</span><br><span class="line">    imgplot = plt.imshow(image.array_to_img(batch[<span class="number">0</span>]))</span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2021/02/05/dl-computer-vision1/p10.png" alt></p>
<p>如果你使用这种数据增强来训练一个新网络，那么网络将不会两次看到同样的输入。<strong>但网 看到的输入仍然是高度相关的，因为这些输入都来自于少量的原始图像</strong>。你无法生成新信息， 而只能混合现有信息。因此，这种方法可能不足以完全消除过拟合。为了进一步降低过拟合， 你还需要向模型中添加一个 Dropout 层，添加到密集连接分类器之前。</p>
<p>Dropout层添加在Flatten操作之后</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.add(layers.Flatten())</span><br><span class="line"><span class="comment"># 添加Dropout层</span></span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br></pre></td></tr></table></figure>
<p>我们再次来训练这个<strong>使用了数据增强和 dropout 的网络</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 注意不能增强验证数据</span></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line">validation_generator = test_datagen.flow_from_directory(</span><br><span class="line">    validation_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">100</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span></span><br><span class="line">)</span><br><span class="line">model.save(<span class="string">'cats_and_dogs_small_2.h5'</span>)</span><br></pre></td></tr></table></figure>
<p>我们再次绘制结果，使用了数据增强和 dropout 之后，模型不再过拟合： 训练曲线紧紧跟随着验证曲线。现在的精度为 82%，比未正则化的模型提高了 15%（相对比例）。</p>
<p><em>实际测试验证精度在77%左右</em></p>
<p>通过进一步使用正则化方法以及调节网络参数（比如每个卷积层的过滤器个数或网络中的 层数），你可以得到更高的精度，可以达到86%或87%。但只靠从头开始训练自己的卷积神经网络， 再想提高精度就十分困难，因为可用的数据太少。想要在这个问题上进一步提高精度，<strong>需要使用预训练的模型</strong>，会在下一篇文章介绍。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/deep-learning/" rel="tag"># deep learning</a>
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/computer-vision/" rel="tag"># computer vision</a>
          
            <a href="/tags/data-augmentation/" rel="tag"># data augmentation</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/01/30/spider-yidun3/" rel="next" title="网易易盾滑动验证码破解（补充篇）">
                <i class="fa fa-chevron-left"></i> 网易易盾滑动验证码破解（补充篇）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/02/26/dl-computer-vision2/" rel="prev" title="深度学习用于计算机视觉(中篇)">
                深度学习用于计算机视觉(中篇) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/uploads/avatar.png" alt="chenxi">
            
              <p class="site-author-name" itemprop="name">chenxi</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">97</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">187</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://docle.github.io/" title="Docle" target="_blank">Docle</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://transformerswsz.github.io/" title="Swift" target="_blank">Swift</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#深度学习用于计算机视觉-上篇"><span class="nav-text">深度学习用于计算机视觉(上篇)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#卷积神经网络简介"><span class="nav-text">卷积神经网络简介</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#卷积运算"><span class="nav-text">卷积运算</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#最大池化"><span class="nav-text">最大池化</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在小数据集上从头开始训练一个卷积神经网络"><span class="nav-text">在小数据集上从头开始训练一个卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#准备数据"><span class="nav-text">准备数据</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#构建网络"><span class="nav-text">构建网络</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#数据预处理"><span class="nav-text">数据预处理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据增强"><span class="nav-text">数据增强</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">chenxi</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  









  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three-waves.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
